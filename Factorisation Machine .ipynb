{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = np.matrix([\n",
    "#    Users  |     Movies     |    Movie Ratings   | Time | Last Movies Rated\n",
    "#   A  B  C | TI  NH  SW  ST | TI   NH   SW   ST  |      | TI  NH  SW  ST\n",
    "    [1, 0, 0,  1,  0,  0,  0,   0.3, 0.3, 0.3, 0,     13,   0,  0,  0,  0 ],\n",
    "    [1, 0, 0,  0,  1,  0,  0,   0.3, 0.3, 0.3, 0,     14,   1,  0,  0,  0 ],\n",
    "    [1, 0, 0,  0,  0,  1,  0,   0.3, 0.3, 0.3, 0,     16,   0,  1,  0,  0 ],\n",
    "    [0, 1, 0,  0,  0,  1,  0,   0,   0,   0.5, 0.5,   5,    0,  0,  0,  0 ],\n",
    "    [0, 1, 0,  0,  0,  0,  1,   0,   0,   0.5, 0.5,   8,    0,  0,  1,  0 ],\n",
    "    [0, 0, 1,  1,  0,  0,  0,   0.5, 0,   0.5, 0,     9,    0,  0,  0,  0 ],\n",
    "    [0, 0, 1,  0,  0,  1,  0,   0.5, 0,   0.5, 0,     12,   1,  0,  0,  0 ]\n",
    "])\n",
    "\n",
    "# ratings\n",
    "y_data = np.array([5, 3, 1, 4, 5, 1, 5])\n",
    "\n",
    "# Let's add an axis to make tensoflow happy.\n",
    "y_data.shape += (1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "n, p = x_data.shape\n",
    "\n",
    "# number of latent factors\n",
    "k = 5\n",
    "\n",
    "# design matrix\n",
    "X = tf.placeholder('float', shape=[n, p])\n",
    "# target vector\n",
    "y = tf.placeholder('float', shape=[n, 1])\n",
    "\n",
    "# bias and weights\n",
    "w0 = tf.Variable(tf.zeros([1]))\n",
    "W = tf.Variable(tf.zeros([p]))\n",
    "\n",
    "# interaction factors, randomly initialized \n",
    "V = tf.Variable(tf.random_normal([k, p], stddev=0.01))\n",
    "\n",
    "# estimate of y, initialized to 0.\n",
    "y_hat = tf.Variable(tf.zeros([n, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates $w_o + \\sum_{i = 1}^{p} w_i x_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_terms = tf.add(w0,\n",
    "        \ttf.reduce_sum(\n",
    "                tf.multiply(W, X), 1, keep_dims=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates $\\frac{1}{2} \\sum_{f = 1}^{k} ((\\sum_{i}^{p} v_{if}x_i)^2 - \\sum_{i = 1}^{p} v_{if}^2 x_i^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interactions = (tf.multiply(0.5,\n",
    "                tf.reduce_sum(\n",
    "                    tf.sub(\n",
    "                        tf.pow( tf.matmul(X, tf.transpose(V)), 2),\n",
    "                        tf.matmul(tf.pow(X, 2), tf.transpose(tf.pow(V, 2)))),\n",
    "                    1, keep_dims=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat = tf.add(linear_terms, interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn the model by minimizing the sum of squares loss function. Add L2 regularization term to prevent overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L2 regularized sum of squares loss function over W and V\n",
    "lambda_w = tf.constant(0.001, name='lambda_w')\n",
    "lambda_v = tf.constant(0.001, name='lambda_v')\n",
    "\n",
    "l2_norm = (tf.reduce_sum(\n",
    "            tf.add(\n",
    "                tf.multiply(lambda_w, tf.pow(W, 2)),\n",
    "                tf.multiply(lambda_v, tf.pow(V, 2)))))\n",
    "\n",
    "error = tf.reduce_mean(tf.square(tf.sub(y, y_hat)))\n",
    "loss = tf.add(error, l2_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model by instantiate Optimizer object and minimize loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eta = tf.constant(0.1)\n",
    "optimizer = tf.train.AdagradOptimizer(eta).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  9.56202e-05\n",
      "Loss (regularized error): 0.00328812\n",
      "Predictions: [[ 5.00942278]\n",
      " [ 1.00716376]\n",
      " [ 4.00393629]\n",
      " [ 5.00835752]\n",
      " [ 1.01295185]\n",
      " [ 3.01246548]\n",
      " [ 5.01098871]]\n",
      "Learnt weights: [ 0.13115798  0.19350205 -0.11888152 -0.01963052 -0.06807373  0.20083955\n",
      "  0.08878157 -0.01278166  0.07432894  0.07578647  0.14581633  0.10008761\n",
      "  0.16054869 -0.18174787  0.08878157  0.        ]\n",
      "Learnt factors: [[-0.1192272  -0.26376137  0.1061745  -0.13125207  0.26142853 -0.2032536\n",
      "  -0.0850707  -0.01416051 -0.06831901 -0.09288774 -0.23749761 -0.25603428\n",
      "  -0.24092621  0.38513494 -0.08550519  0.00335897]\n",
      " [ 0.09893265  0.23286533 -0.14457522  0.11698433 -0.27972937  0.19220932\n",
      "   0.04177043 -0.01598943  0.05023088  0.046404    0.21351211  0.276452\n",
      "   0.22398117 -0.42053214  0.04309372  0.00078712]\n",
      " [-0.1039304  -0.27868834  0.14098421 -0.12209997  0.28104118 -0.20802394\n",
      "  -0.07553737  0.0118631  -0.04986483 -0.09383552 -0.23956515 -0.27726933\n",
      "  -0.24224874  0.42145225 -0.0744479  -0.00319736]\n",
      " [ 0.11429872 -0.03046226 -0.13362937  0.12207457 -0.10568042  0.04733804\n",
      "  -0.06928673 -0.01276423  0.08334956 -0.02251736 -0.02792878  0.05391975\n",
      "   0.05562277 -0.04616206 -0.0723009   0.00349462]\n",
      " [-0.09596669  0.01832989  0.12155366 -0.1223542   0.15227257 -0.09987909\n",
      "   0.08989827  0.00330196 -0.12409302  0.01767823  0.03005389 -0.10396013\n",
      "  -0.15909317  0.13461243  0.09384622 -0.0009108 ]]\n"
     ]
    }
   ],
   "source": [
    "# that's a lot of iterations\n",
    "N_EPOCHS = 1000\n",
    "# Launch the graph.\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        indices = np.arange(n)\n",
    "        np.random.shuffle(indices)\n",
    "        x_data, y_data = x_data[indices], y_data[indices]\n",
    "        sess.run(optimizer, feed_dict={X: x_data, y: y_data})\n",
    "\n",
    "    print('MSE: ', sess.run(error, feed_dict={X: x_data, y: y_data}))\n",
    "    #print('Loss (regularized error):', sess.run(cost, feed_dict={X: x_data, y: y_data}))\n",
    "    print('Loss (regularized error):', sess.run(loss, feed_dict={X: x_data, y: y_data}))\n",
    "    print('Predictions:', sess.run(y_hat, feed_dict={X: x_data, y: y_data}))\n",
    "    print('Learnt weights:', sess.run(W, feed_dict={X: x_data, y: y_data}))\n",
    "    print('Learnt factors:', sess.run(V, feed_dict={X: x_data, y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
